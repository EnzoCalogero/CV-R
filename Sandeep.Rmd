---
title: "C:Drive Performance After Enabling the Controller Cache"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Objective 
```{r,echo=FALSE}
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```
The objective of this experiment is to identify the impact of enabling the cache on the controller for the C: drive on  Media Agents and  CommServer. 

## Result Summary

#### Media Agents
The change of configuration improved the performance of  Media Agents on the backup Index phase.
The configuration has little impact on the  Operating System Activity or other CommVault Operations.


#### CommServer
The change of configuration does not bring any improvement and, occasionally, decreases the performance of the  Operating System ,Microsoft SQL server and CommVault slightly.


## Experiment Description


### Data descriptions  
For defining impact of the configuration change on performance the following has been collected and analysed.

1. 3 counters were take into account from  Microsoft Performance Monitor.
    + **"PhysicalDisk -- Disk Transfer/Sec"**       --> has an estimator of the IOPS
    + **"PhysicalDisk -- Avg Disk Sec/Transfer"**   --> has an estimator of the Response Time (or Latency) 
    + **"PhysicalDisk -- Avg Disk Queue Length"**   --> has an estimator of queue associated with IOPS and latency.

2. The counters were collected one week before the change, and one week after.
    + Data Set **"Before"**  from 16/09 00:00 to 22/09 23:59;
    + Data set **"Skipped"** from 23/09 00:00 to 23/09 23:59 (Day of the change, NOT considered for the analysis);
    + Data Set **"After"** from 24/09 00:00 to 30/09 23:59.
        
3.  The three counters have a sampling span time of 15 seconds. In other words we have a 4 records for each minutes, and its the sampled average of the 15 seconds interval.

###Motivation for the selected counters and modelling used

The aim of the experiment is to identify the performance impact of the configuration change. The main challenge is to use the production workload, and NOT a predefined workload (like in a lab controlled environment).

Therefore we need to identify a comparative model and identify the key elements.
Since it is known that the Response Time or latency is workload depended, we need to identify the relation between the workload and the performance in the two scenarios (cache on/Off) and establish which is the better one.  


$$Performance=f_{Status\ Cache}(Worload)$$

The best and reliable function that links the IOPS with performance is the evergreen **Little Law Theorem**, where 
  + the length of the Queue can be considerate the "Stress" of the system or the degradation of the performance.
  + The response time could be considered an indicator of performance.
  + IOPS could be considered an indicator of workload.

$$Queue=Response\ Time \bullet IOPS$$

note: 
The formula was used to validate the data $\frac{Queue}{Response\ Time \cdot IOPS}\cong 1$ and it holds for each record used in the analysis.

To be more precise in the analysis was included the *Service time* as well, since it is independent from the queue, it provides an additional information for the performance analysis:

$Response\ Time= Service\ Time \cdot (Queue+1)$


##Overview of the Collected Data.


The picture below shows the trend for the 3 counters considered

Line definitions:

  1. **Red line    --> IOPS**
  2. **Green line  --> Latency**
  3. **Blue Line   --> Queue Length**

###Media Agents
The picture below shows the counters trend during 15 days of the experiment. 
(It is shown the only MA04, but all the Media Agents showed a similar pattern).

!["Media Agent Trend From Performance Monitor"](C:\Users\enzo7311\Desktop\Sandeep_CWS403\MA4\2WeeksTrend.png)

From the graph we can see that the queue length is generally less intense on the right side (when the cache was enabled) , but unfortunately the IOPS (~ the workload) is not uniform in the two weeks, therefore this graph can not be used to identify the  impact.

###CommServer
!["CommServer Trend From Performance Monitor"](C:\Users\enzo7311\Desktop\Sandeep_CWS403\CS\2WeeksTrend.png)
From the graph the difference are not perceptible. The pattern of the two weeks is extremely similar.



##Statistics Overview


For analyzing the impact three different analysis have been done.

1. Distribution analysis: the four metrics (IOPS, Response Time, Queue Length, Service Time) are compared before and after the modification.  Where  can be seen the general impact due to the modification.
2. Variance of the Data by the Hour: For each hour of  day the median of each week is compared for the 4 metrics.  
3. Time Series analysis decomposition: where the data has been decomposed into the  daily cycle, trend and uncorrelated error.



#Media agent

## 1. Distributions
```{r,echo=FALSE,message=FALSE}
##This part is related to teh Media Agent analysis....
  library(dplyr)
  library(lubridate) #Date management
  library(ggplot2)
file='C:/Users/enzo7311/Desktop/timeseries/ma04/Ma04.csv'
dati<- read.csv(file,sep=';')              #Read the data 
dati$time<-mdy_hm(dati$time)               #transform time into lubridate format
dati$hour<-hour(dati$time)                 #Exctract the hour from the time
#Clear the data
dati<-subset(dati,dati$Time.Position != "") 
dati<-subset(dati,dati$Time.Position != "NULLLLLA")
dati$Time.Position<-factor(dati$Time.Position,level=c("Before","After"))
#trasform the variable into more meaningfull term
dati$queue<-dati$Avg..Disk.Queue.Length
dati$R<-dati$Avg..Disk.sec.Transfer
dati$IOPS<-dati$Disk.Transfers.sec
dati$Avg..Disk.Queue.Length<-NULL
dati$Avg..Disk.sec.Transfer<-NULL
dati$Disk.Transfers.sec<-NULL
#create the Service time column
dati$S<-dati$R/(dati$queue+1)

````

All the metrics are plotted in log scale, to allow a  better graphical representation.
The following can be noted:


1. It can be seen the **IOPS** (which in the context is the workload), in the two weeks (before and After) is similar but not identical.
    + In particular in the second week, the Workload was less that the first one.
    + This increase the difficulty of the analysis, because we need to identify if the reduced workload is the reason for the change  on the performance metric.

2. **The Response Time, Service Time** Even if the two graphs have a similar pattern in the two weeks, they show a shift of the distributions to the left, which means a performance improvement. 

  

```{r,echo=FALSE,warning=FALSE}
ggplot(dati, aes(x=log(IOPS))) + geom_density(color="blue", fill="lightblue") +ggtitle("IOPS")+xlab("IOPS in log scale")+ facet_grid(.~ Time.Position )
ggplot(dati, aes(x=log(R))) + geom_density(color="blue", fill="lightblue") +ggtitle("Response Time ")+xlab("Response Time in log scale")+ facet_grid(.~ Time.Position )
ggplot(dati, aes(x=log(queue))) + geom_density(color="blue", fill="lightblue") +ggtitle("Queue Lenght")+xlab("Queue Lenght in log scale")+ facet_grid(.~ Time.Position )
ggplot(dati, aes(x=log(S))) + geom_density(color="blue", fill="lightblue") +ggtitle("Service Time")+xlab("Service Time in log scale")+ facet_grid(.~ Time.Position )
```

###2. Variance of the Data by the Hour
The following graphs show the variability for each  considered variable.

1. The **IOPS-WOrkload** is extremely low for most of the day the increase of the load is from 9pm to 3am as expected.
    + the variability between the 2 weeks can be considerate low, which is expected as the two weeks should have the same load.
2. The most relevant parameter for analyzing the performance is the Service time (response Time /Queue Length) as it rap present the amount of time taken on average for a single IOPS.
    + we can see that nearly all the the hours considerate have an improvement (except the midnight one).
    
3. Consequentially the queue length is reduced for most of the hours (except the 10pm the 3 am and 1 pm).

4. the Response time is constantly improved in all the hours.

```{r,echo=FALSE,message=FALSE,warning=FALSE,fig.width=13,fig.height=12}
#Data Aggregation

 #dati$Time.Position<-as.numeric(dati$Time.Position)
DatiAgg2<-dati %>% group_by(Time.Position,hour) %>% summarise(medianQueue=median(queue),mediaQueue=mean(queue),sdQueue=sd(queue),medianR=median(R),mediaR=mean(R),sdR=sd(R),medianIOPS=median(IOPS),mediaIOPS=mean(IOPS),SdIOPS=sd(IOPS),medianS=median(S),mediaS=mean(S),sdS=sd(S))

#Plotting
p1<-ggplot(DatiAgg2, aes(factor(hour), medianIOPS))+ggtitle("IOPS - (Workload)")+ylab("Median value for IOPS ") +xlab("Hours")+ geom_boxplot()+ geom_point(aes(colour = Time.Position),size=3)
p2<-ggplot(DatiAgg2, aes(factor(hour), medianQueue))+ggtitle("Queue Lenght")+ylab("Median value for Queue Lenght ") +xlab("Hours")+ geom_boxplot()+ geom_point(size=3,aes(colour = Time.Position))
p3<-ggplot(DatiAgg2, aes(factor(hour), medianR)) +ggtitle("Response Time")+ylab("Median value for Response Time ")+xlab("Hours")+ geom_point(aes(colour = Time.Position),size=3)+ geom_boxplot()
p4<-ggplot(DatiAgg2, aes(factor(hour), medianS)) +ggtitle("Service Time ")+ylab("Median value for Service Time ")+xlab("Hours")+ geom_boxplot()+ geom_point(aes(colour = Time.Position),size=4)
multiplot(p1,p2,p3,p4, cols=2)
```

The aggregate values of the 4 counters during the 2 weeks of the experiment.

```{r,echo=FALSE,warning=FALSE}
library(knitr)
 DatiAgg<-dati %>% group_by(Time.Position) %>% summarise(Median_IOPS=median(IOPS),Median_Queue=median(queue),Median_Response=median(R),Median_Service=median(S))
DatiAgg$Median_IOPS<-round(DatiAgg$Median_IOPS,1)
DatiAgg$Median_Queue<-round(DatiAgg$Median_Queue,3)
DatiAgg$Median_Response<-round(DatiAgg$Median_Response,5)
DatiAgg$Median_Service<-round(DatiAgg$Median_Service,5)

kable(DatiAgg, format = "markdown")

```

##3. Time Series Analysis

the time series (the value of the contaminator every 15 second) of the 4 metrics have been decomposed into the 3 temporal component 
1. Daily cycle (the variation of the value of the metric due to the daily scheduling)
2. The trend 
3. The uncorrelated part of the time series(normally called noise).


All the graphs show a performance improvement in the second week.
(Except the IOPS that shows a similar trend for the two weeks)

```{r, echo=FALSE,warning=FALSE,fig.width=7,fig.height=7}
  freq<-4*60*24
  dati<-read.csv(file,sep=';')
  dati$queue<-dati$Avg..Disk.Queue.Length
  dati$R<-dati$Avg..Disk.sec.Transfer
  dati$IOPS<-dati$Disk.Transfers.sec
  dati$S<-dati$R/(dati$queue+1)   
  dati$Time.Position<-as.character(dati$Time.Position)
  dati<-subset(dati,dati$Time.Position != "")
  
  iops<-ts(dati$IOPS, start = c(3, 17),frequency=(freq))
  
  fit<-stl(iops,s.window="periodic")
  
  plot(fit,main="IOPS",col.range="red",labels=c("Observate Time Serie","Daily Cycle","Trend","Random"))

  Queue<-ts(dati$queue, start = c(3, 17),frequency=(freq))
  
  fit<-stl(Queue,s.window="periodic")
  plot(fit,main="Queue Lenght",col.range="red",labels=c("Observate Time Serie","Daily Cycle","Trend","Random"))
  
  response<-ts(dati$R, start = c(3, 17),frequency=(freq))
  
  fit<-stl(response,s.window="periodic")
  
  
  plot(fit,main="Response Time",col.range="red",labels=c("Observate Time Serie","Daily Cycle","Trend","Random"))
  
  
  
  S<-ts(dati$S, start = c(3, 17),frequency=(freq))
  
  fit<-stl(S,s.window="periodic")
  
  plot(fit,main="Service Time",col.range="red",labels=c("Observate Time Serie","Daily Cycle","Trend","Random"))
  
```

#CommServer
```{r,echo=FALSE,message=FALSE}
##This part is related to teh Media Agent analysis....
  library(dplyr)
  library(lubridate) #Date management
  library(ggplot2)
file='C:/Users/enzo7311/Desktop/timeseries/cs403/cs403.csv'
dati<- read.csv(file,sep=';')              #Read the data 
dati$time<-mdy_hm(dati$time)               #transform time into lubridate format
dati$hour<-hour(dati$time)                 #Exctract the hour from the time
#Clear the data
dati<-subset(dati,dati$Time.Position != "") 
dati<-subset(dati,dati$Time.Position != "NULLLLLA")
dati$Time.Position<-factor(dati$Time.Position,level=c("Before","After"))
#trasform the variable into more meaningfull term
dati$queue<-dati$Avg..Disk.Queue.Length
dati$R<-dati$Avg..Disk.sec.Transfer
dati$IOPS<-dati$Disk.Transfers.sec
dati$Avg..Disk.Queue.Length<-NULL
dati$Avg..Disk.sec.Transfer<-NULL
dati$Disk.Transfers.sec<-NULL
#create the Service time column
dati$S<-dati$R/(dati$queue+1)

````


## 1. Distributions

Looking to each distribution of the variable:

1. It can be seen the **IOPS** (which in the context is the workload), in the two weeks (before and After) is practically identical.
    

2. **The Response Time, Service Time** graphs are extremely similar in the two weeks showing no impact on the second week.


```{r,echo=FALSE,warning=FALSE}
ggplot(dati, aes(x=log(IOPS))) + geom_density(color="blue", fill="lightblue") +ggtitle("IOPS")+xlab("IOPS in log scale")+ facet_grid(.~ Time.Position )
ggplot(dati, aes(x=log(R))) + geom_density(color="blue", fill="lightblue") +ggtitle("Response Time ")+xlab("Response Time in log scale")+ facet_grid(.~ Time.Position )
ggplot(dati, aes(x=log(queue))) + geom_density(color="blue", fill="lightblue") +ggtitle("Queue Lenght")+xlab("Queue Lenght in log scale")+ facet_grid(.~ Time.Position )
ggplot(dati, aes(x=log(S))) + geom_density(color="blue", fill="lightblue") +ggtitle("Service Time")+xlab("Service Time in log scale")+ facet_grid(.~ Time.Position )
```

###2. Variance of the Data by the Hour
The following graphs show the variability for each  considered variable.

1. The **IOPS-WOrkload** is extremely low for most of the day the increase of the load is from 9pm to 6am as expected.
    + the variability between the 2 weeks can be considerate low, which is expected as the two weeks should have the same load.
2. The most relevant parameter for analyzing the performance is the Service time (response Time /Queue Length) as it represent the amount of time taken on average for a single IOPS.
    + we can see that there is no a clear improvement and in specif hour of the day, the second week has a worst performance.
    
3. The queue length does not show an improvement and often has a decrease of performance.

4. the Response time does not show an improvement and often has a decrease of performance.

```{r,echo=FALSE,message=FALSE,warning=FALSE,fig.width=13,fig.height=12}
#Data Aggregation

 #dati$Time.Position<-as.numeric(dati$Time.Position)
DatiAgg2<-dati %>% group_by(Time.Position,hour) %>% summarise(medianQueue=median(queue),mediaQueue=mean(queue),sdQueue=sd(queue),medianR=median(R),mediaR=mean(R),sdR=sd(R),medianIOPS=median(IOPS),mediaIOPS=mean(IOPS),SdIOPS=sd(IOPS),medianS=median(S),mediaS=mean(S),sdS=sd(S))

#Plotting
p1<-ggplot(DatiAgg2, aes(factor(hour), medianIOPS))+ggtitle("IOPS - (Workload)")+ylab("Median value for IOPS ") +xlab("Hours")+ geom_boxplot()+ geom_point(aes(colour = Time.Position),size=3)
p2<-ggplot(DatiAgg2, aes(factor(hour), medianQueue))+ggtitle("Queue Lenght")+ylab("Median value for Queue Lenght ") +xlab("Hours")+ geom_boxplot()+ geom_point(size=3,aes(colour = Time.Position))
p3<-ggplot(DatiAgg2, aes(factor(hour), medianR)) +ggtitle("Response Time")+ylab("Median value for Response Time ")+xlab("Hours")+ geom_point(aes(colour = Time.Position),size=3)+ geom_boxplot()
p4<-ggplot(DatiAgg2, aes(factor(hour), medianS)) +ggtitle("Service Time ")+ylab("Median value for Service Time ")+xlab("Hours")+ geom_boxplot()+ geom_point(aes(colour = Time.Position),size=4)
multiplot(p1,p2,p3,p4, cols=2)
```

The aggregate values of the 4 counters during the 2 weeks of the experiment.

```{r,echo=FALSE,warning=FALSE}
library(knitr)
 DatiAgg<-dati %>% group_by(Time.Position) %>% summarise(Median_IOPS=median(IOPS),Median_Queue=median(queue),Median_Response=median(R),Median_Service=median(S))
DatiAgg$Median_IOPS<-round(DatiAgg$Median_IOPS,2)
DatiAgg$Median_Queue<-round(DatiAgg$Median_Queue,5)
DatiAgg$Median_Response<-round(DatiAgg$Median_Response,7)
DatiAgg$Median_Service<-round(DatiAgg$Median_Service,7)

kable(DatiAgg, format = "markdown")

```

##3. Time Series Analysis

the time series (the value of the contaminator every 15 second) of the 4 metrics have been decomposed into the 3 temporal component 
1. Daily cycle (the variation of the value of the metric due to the daily scheduling)
2. The trend 
3. The uncorrelated part of the time series( normally called noise).


All the next analysis do not show an improvement in the second week...
```{r, echo=FALSE,warning=FALSE,fig.width=7,fig.height=7}
  freq<-4*60*24
  dati<-read.csv(file,sep=';')
  dati$queue<-dati$Avg..Disk.Queue.Length
  dati$R<-dati$Avg..Disk.sec.Transfer
  dati$IOPS<-dati$Disk.Transfers.sec
  dati$S<-dati$R/(dati$queue+1)   
  dati$Time.Position<-as.character(dati$Time.Position)
  dati<-subset(dati,dati$Time.Position != "")

  iops<-ts(dati$IOPS, start = c(3, 17),frequency=(freq))
  
  fit<-stl(iops,s.window="periodic")
  
  plot(fit,main="IOPS",col.range="red",labels=c("Observate Time Serie","Daily Cycle","Trend","Random"))

  Queue<-ts(dati$queue, start = c(3, 17),frequency=(freq))
  
  fit<-stl(Queue,s.window="periodic")
  plot(fit,main="Queue Lenght",col.range="red",labels=c("Observate Time Serie","Daily Cycle","Trend","Random"))
  
  response<-ts(dati$R, start = c(3, 17),frequency=(freq))
  
  fit<-stl(response,s.window="periodic")
  
  
  plot(fit,main="Response Time",col.range="red",labels=c("Observate Time Serie","Daily Cycle","Trend","Random"))
  
  
  
  S<-ts(dati$S, start = c(3, 17),frequency=(freq))
  
  fit<-stl(S,s.window="periodic")
  
  plot(fit,main="Service Time",col.range="red",labels=c("Observate Time Serie","Daily Cycle","Trend","Random"))
  
```

